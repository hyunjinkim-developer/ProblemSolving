{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deciding on a primary metric\n",
    "## Confusion Matrix\n",
    "![confusion_matrix](https://t1.daumcdn.net/cfile/tistory/99DC064C5BE056CE10?original)\n",
    "True라고 예측한 경우 -> Posiitive\n",
    "True Positive(TP) : 실제 True인 정답을 True라고 예측 (정답)\n",
    "False Positive(FP) : 실제 False인 정답을 True라고 예측 (오답)\n",
    "False라고 예측한 경우 -> Negative\n",
    "False Negative(FN) : 실제 True인 정답을 False라고 예측 (오답)\n",
    "True Negative(TN) : 실제 False인 정답을 False라고 예측 (정답)\n",
    "\n",
    "## Precision(정밀도)\n",
    "### := 모델이 True라고 분류한 것 중에서 실제 True인 것의 비율\n",
    "![Precision](https://t1.daumcdn.net/cfile/tistory/99F66B345BE0596109)\n",
    "\n",
    "## Recall(재현율)\n",
    "### := 실제 True인 것 중에서 모델이 True라고 예측한 것의 비율\n",
    "![Recall](https://t1.daumcdn.net/cfile/tistory/997188435BE05B0628)\n",
    "\n",
    "## Accuracy(정확도)\n",
    "### := True를 True라고, False를 False라고 옳게 예측한 경우\n",
    "![Accuracy](https://t1.daumcdn.net/cfile/tistory/99745F3F5BE0613D1A)\n",
    "\n",
    "## F1 score\n",
    "### := Precision과 Recall의 조화평균\n",
    "![F1 Score](https://t1.daumcdn.net/cfile/tistory/993482335BE0641515)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A model predicting the presence of cancer as the positive class.\n",
    "# -> This model should minimize the number of false negatives, so recall is a more appropriate metric.\n",
    "\n",
    "# A classifier predicting the positive class of a computer program containing malware.\n",
    "# -> To avoid installing malware, false negatives should be minimized, hence recall or F1-score are better metrics for this model.\n",
    "\n",
    "# A model predicting if a customer is a high-value lead for a sales team with limited capacity.\n",
    "# -> With limited capacity, the sales team needs the model to return the highest proportion of true positives compared to all predicted positives, thus minimizing wasted effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "# The support is the number of occurrences of each class in y_true."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict probability"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "# logreg.predict_proba(X_test) returns the probability of the sample for each class in the model, where classes are ordered as they are in self.classes_.\n",
    "y_pred_probs = logreg.predict_proba(X_test)[:, 1] # Probability of having a diabetes diagnosis\n",
    "\n",
    "print(y_pred_probs[:10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ROC curve"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import roc_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--') # Randomly guessing the class of each observation.\n",
    "\n",
    "# Plot tpr against fpr\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Diabetes Prediction')\n",
    "plt.show()\n",
    "# The ROC curve is above the dotted line, so the model performs better than randomly guessing the class of each observation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Calculate roc_auc_score\n",
    "# roc_auc_score(y_true, y_score)\n",
    "# y_score :=\n",
    "# In the multilabel case, it corresponds to an array of shape (n_samples, n_classes). Probability estimates are provided by the predict_proba method and the non-thresholded decision values by the decision_function method.\n",
    "print(roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calculate the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter tuing with GridSearchCV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid = {\"alpha\": np.linspace(start=0.00001, stop=1, num=20)}\n",
    "\n",
    "# Instantiate lasso_cv\n",
    "lasso_cv = GridSearchCV(lasso, param_grid, cv=kf)\n",
    "\n",
    "# Fit to the training data\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "print(\"Tuned lasso paramaters: {}\".format(lasso_cv.best_params_))\n",
    "print(\"Tuned lasso score: {}\".format(lasso_cv.best_score_))\n",
    "# Highlighting that using the optimal hyperparameters does not guarantee a high performing model!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter tuing with  RandomizedSearchCV\n",
    "tests a fixed number of hyperparameter settings from specified probability distributions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the parameter space\n",
    "params = {\"penalty\": [\"l1\", \"l2\"],\n",
    "         \"tol\": np.linspace(0.0001, 1.0, 50),\n",
    "         \"C\": np.linspace(0.1, 1.0, 50),\n",
    "         \"class_weight\": [\"balanced\", {0:0.8, 1:0.2}]}\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "logreg_cv = RandomizedSearchCV(logreg, params, cv=kf)\n",
    "\n",
    "# Fit the data to the model\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Best Accuracy Score: {}\".format(logreg_cv.best_score_))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
