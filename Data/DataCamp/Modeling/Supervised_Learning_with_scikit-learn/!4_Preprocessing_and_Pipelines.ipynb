{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing and Pipelines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing categorical features into numeric values\n",
    " * pandas.get_dummies()\n",
    " * sklearn.preprocessing.OneHotEncoder()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of music_dummies: (1000, 12)\n"
     ]
    }
   ],
   "source": [
    "# Create music_dummies\n",
    "music_dummies = pd.get_dummies(music_df, drop_first=True)\n",
    "\n",
    "# Print the new DataFrame's shape\n",
    "print(\"Shape of music_dummies: {}\".format(music_dummies.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 10.356167918309259\n",
      "Standard Deviation of the target array: 14.02156909907019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create X and y\n",
    "X = music_dummies.drop(\"popularity\", axis=\"columns\")\n",
    "y = music_df[\"popularity\"]\n",
    "\n",
    "# Instantiate a ridge model\n",
    "ridge = Ridge(alpha=0.2)\n",
    "\n",
    "# Perform cross-validation\n",
    "# scoring parameters:\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules\n",
    "scores = cross_val_score(ridge, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(-scores)\n",
    "print(\"Average RMSE: {}\".format(np.mean(rmse)))\n",
    "print(\"Standard Deviation of the target array: {}\".format(np.std(y)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dropping missing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n",
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n",
      "['popularity', 'acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence', 'genre']\n",
      "       popularity  acousticness  danceability  duration_ms  energy  \\\n",
      "36506        60.0      0.896000         0.726     214547.0  0.1770   \n",
      "37591        63.0      0.003840         0.635     190448.0  0.9080   \n",
      "37658        59.0      0.000075         0.352     456320.0  0.9560   \n",
      "36060        54.0      0.945000         0.488     352280.0  0.3260   \n",
      "35710        55.0      0.245000         0.667     273693.0  0.6470   \n",
      "...           ...           ...           ...          ...     ...   \n",
      "44501        57.0      0.972000         0.193     208040.0  0.0329   \n",
      "25114        56.0      0.005790         0.939     144453.0  0.3730   \n",
      "46896        54.0      0.016100         0.739     238339.0  0.5390   \n",
      "45135        62.0      0.326000         0.515     286707.0  0.5050   \n",
      "18960        42.0      0.029500         0.291     194679.0  0.5980   \n",
      "\n",
      "       instrumentalness  liveness  loudness  speechiness    tempo  valence  \\\n",
      "36506          0.000002    0.1160   -14.824       0.0353   92.934   0.6180   \n",
      "37591          0.083400    0.2390    -4.795       0.0563  110.012   0.6370   \n",
      "37658          0.020300    0.1250    -3.634       0.1490  122.897   0.2280   \n",
      "36060          0.015700    0.1190   -12.020       0.0328  106.063   0.3230   \n",
      "35710          0.000297    0.0633    -7.787       0.0487  143.995   0.3000   \n",
      "...                 ...       ...       ...          ...      ...      ...   \n",
      "44501          0.929000    0.0978   -28.228       0.0460   82.165   0.0366   \n",
      "25114          0.000000    0.2740    -7.779       0.2270  119.953   0.0602   \n",
      "46896          0.000000    0.2350    -9.735       0.3370   85.082   0.8350   \n",
      "45135          0.000000    0.1020    -5.606       0.0294  150.063   0.5380   \n",
      "18960          0.002270    0.0738    -6.972       0.0394  146.245   0.1860   \n",
      "\n",
      "       genre  \n",
      "36506      1  \n",
      "37591      1  \n",
      "37658      1  \n",
      "36060      1  \n",
      "35710      1  \n",
      "...      ...  \n",
      "44501      0  \n",
      "25114      0  \n",
      "46896      0  \n",
      "45135      0  \n",
      "18960      0  \n",
      "\n",
      "[1000 rows x 12 columns]\n",
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n",
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "loudness            0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "valence             0\n",
      "genre               0\n",
      "dtype: int64\n",
      "Shape of the `music_df`: (1000, 12)\n",
      "[1 0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Print the number of missing values for each column in the music_df dataset, sorted in ascending order.\n",
    "print(music_df.isna().sum().sort_values())\n",
    "\n",
    "\n",
    "# Print missing values for each column\n",
    "missing_values_count = music_df.isna().sum().sort_values()\n",
    "print(missing_values_count)\n",
    "\n",
    "subset = list(missing_values_count[missing_values_count < 50].index)\n",
    "print(subset)\n",
    "\n",
    "# Remove values where less than 5%(50 or fewer) are missing\n",
    "# music_df = music_df.dropna(subset=['genre', 'popularity', 'loudness', 'liveness', 'tempo'])\n",
    "music_df = music_df.dropna(subset=subset)\n",
    "print(music_df)\n",
    "\n",
    "\n",
    "# Print missing values for each column\n",
    "print(music_df.isna().sum().sort_values())\n",
    "\n",
    "# Remove values where less than 5% are missing\n",
    "music_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])\n",
    "print(music_df.isna().sum().sort_values())\n",
    "print(\"Shape of the `music_df`: {}\".format(music_df.shape))\n",
    "\n",
    "# Convert genre to a binary feature\n",
    "print(pd.unique(music_df[\"genre\"].values))\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "print(pd.unique(music_df[\"genre\"].values))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Instantiate an imputer\n",
    "imputer = SimpleImputer()\n",
    "\n",
    "# Instantiate a knn model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Build steps for the pipeline\n",
    "steps = [(\"imputer\", imputer),\n",
    "         (\"knn\", knn)]\n",
    "\n",
    "\n",
    "steps = [(\"imputer\", imp_mean),\n",
    "        (\"knn\", knn)]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Centering and Scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create pipeline steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"lasso\", Lasso(alpha=0.5))]\n",
    "\n",
    "# Instantiate the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate and print R-squared\n",
    "print(pipeline.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# Build the steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"logreg\", LogisticRegression())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create the parameter space\n",
    "# np.linspace := Return evenly spaced numbers over a specified interval.\n",
    "# logistic regression model's C hyperparameter within the pipeline -> logreg__C\n",
    "parameters = {\"logreg__C\": np.linspace(start=0.001, stop=1.0, num=20)}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "random_state=21)\n",
    "\n",
    "# Instantiate the grid search object\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "# Fit to the training data\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, \"\\n\", cv.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating multiple models\n",
    "![metrics](./images/metrics_for_model_performace.png)\n",
    "![Models_affected_by_scaling.png](./images/Models_affected_by_scaling.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = {\"Linear Regression\": LinearRegression(), \"Ridge\": Ridge(alpha=0.1), \"Lasso\": Lasso(alpha=0.1)}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "\n",
    "  # Perform cross-validation\n",
    "  cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "\n",
    "  # Append the results\n",
    "  results.append(cv_scores)\n",
    "\n",
    "# Create a box plot of the results\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "  # Fit the model to the training data\n",
    "  model.fit(X_train_scaled, y_train)\n",
    "\n",
    "  # Make predictions on the test set\n",
    "  y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "  # Calculate the test_rmse\n",
    "  test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "  print(\"{} Test Set RMSE: {}\".format(name, test_rmse))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create models dictionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(), \"KNN\": KNeighborsClassifier(), \"Decision Tree Classifier\": DecisionTreeClassifier()}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "\n",
    "  # Instantiate a KFold object\n",
    "  kf = KFold(n_splits=6, random_state=12, shuffle=True)\n",
    "\n",
    "  # Perform cross-validation\n",
    "  cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "  results.append(cv_results)\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create steps\n",
    "steps = [(\"imp_mean\", SimpleImputer()),\n",
    "         (\"scaler\", StandardScaler()),\n",
    "         (\"logreg\", LogisticRegression())]\n",
    "\n",
    "# Set up pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "params = {\"logreg__solver\": [\"newton-cg\", \"saga\", \"lbfgs\"],\n",
    "         \"logreg__C\": np.linspace(0.001, 1.0, 10)}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "tuning = GridSearchCV(pipeline, param_grid=params)\n",
    "tuning.fit(X_train, y_train)\n",
    "y_pred = tuning.predict(X_test)\n",
    "\n",
    "# Compute and print performance\n",
    "print(\"Tuned Logistic Regression Parameters: {}, Accuracy: {}\".format(tuning.best_params_, tuning.score(X_test, y_test)))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
